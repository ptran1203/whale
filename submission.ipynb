{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble of 4 models\n",
      "Ensemble from 4 models ['infer\\\\b5_pseudo_cutout_lb0.836', 'infer\\\\b5_pseudo_lb0.832', 'infer\\\\b5_pseudo_lb0.833', 'infer\\\\b6_pseudo_lb0.83x']\n",
      "Ensemble from 4 models ['infer\\\\b5_pseudo_cutout_lb0.836', 'infer\\\\b5_pseudo_lb0.832', 'infer\\\\b5_pseudo_lb0.833', 'infer\\\\b6_pseudo_lb0.83x']\n"
     ]
    }
   ],
   "source": [
    "from utils import pickle_load\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import os\n",
    "from glob import glob\n",
    "from evaluate import compute_sim, evaluate, l2norm_numpy\n",
    "from evaluate import dict2list\n",
    "\n",
    "def l2norm(embs):\n",
    "    return {k: v/np.linalg.norm(v) for k, v in embs.items()}\n",
    "\n",
    "infer_dirs = glob('infer/*')[:]\n",
    "# infer_dirs = infer_dirs[1:]\n",
    "infer_dirs = [x for x in infer_dirs if 'bk' not in x and 'eval' not in x]\n",
    "# infer_dirs = [x for x in infer_dirs if 'b5_noexpand_pseudo_lb0.82' in  x]\n",
    "weights = [1.0] * len(infer_dirs)\n",
    "# weights = [1.0, 0.5, 0.5]\n",
    "\n",
    "print(f\"Ensemble of {len(infer_dirs)} models\")\n",
    "\n",
    "submit_file = f'submission.csv'\n",
    "if os.path.exists('D:/whale_data/train_images-384-384/train_images-384-384'):\n",
    "    train_img_dir = 'D:/whale_data/train_images-384-384/train_images-384-384'\n",
    "else:\n",
    "    train_img_dir = '/Users/macbook/works/train_images-384-384'\n",
    "\n",
    "norm=True\n",
    "method = 'cat'\n",
    "\n",
    "def get_emb(infer_dirs, subset, weights):\n",
    "    li = []\n",
    "    for infer_dir in infer_dirs:\n",
    "        if isinstance(subset, str):\n",
    "            embs = pickle_load(f\"{infer_dir}/{subset}_emb.pkl\")\n",
    "        else:\n",
    "            embs = {}\n",
    "            for s in subset:\n",
    "                p = f\"{infer_dir}/{s}_emb.pkl\"\n",
    "                if os.path.exists(p):\n",
    "                    embs = {**embs, **pickle_load(p)}\n",
    "                elif s != \"val\":\n",
    "                    raise FileNotFoundError(p)\n",
    "\n",
    "        li.append(embs)\n",
    "\n",
    "    if len(li) == 1:\n",
    "        return li[0]\n",
    "\n",
    "    print(f'Ensemble from {len(infer_dirs)} models {infer_dirs}')\n",
    "    li0 = li[0]\n",
    "    di = {}\n",
    "    for k in li0.keys():\n",
    "        di[k] = []\n",
    "        for i in range(len(li)):\n",
    "            e = li[i][k]\n",
    "            if norm:\n",
    "                e = e / np.linalg.norm(e)\n",
    "            di[k].append(e)\n",
    "        \n",
    "        if method == 'cat':\n",
    "            di[k] = np.concatenate(di[k], 0)\n",
    "        else:\n",
    "            # Mean\n",
    "            di[k] = np.mean(di[k], 0)\n",
    "\n",
    "    return di\n",
    "\n",
    "train_df = pd.read_csv('data/train_kfold.csv')\n",
    "\n",
    "run_val = False\n",
    "try:\n",
    "    train_embs = get_emb(infer_dirs, 'train', weights)\n",
    "    test_embs = get_emb(infer_dirs, 'test', weights)\n",
    "    val_embs = get_emb(infer_dirs, 'val', weights)\n",
    "\n",
    "    train_embs = l2norm(train_embs)\n",
    "    test_embs = l2norm(test_embs)\n",
    "    val_embs = l2norm(val_embs)\n",
    "    run_val = True\n",
    "    print(len(train_embs) + len(val_embs))\n",
    "except:\n",
    "    pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "val_df = train_df[train_df.subset == 'test'].reset_index()\n",
    "val_map = dict(zip(val_df.image, val_df.individual_id))\n",
    "train_map = dict(zip(train_df.image, train_df.individual_id))\n",
    "spec_map = dict(zip(train_df.image, train_df.species))\n",
    "id_map = {**train_map, **val_map}\n",
    "# val_imgs = val_df.image.unique()\n",
    "# val_embs = {k: train_embs[k] for k in val_imgs}\n",
    "with open('individual_ids.json', 'r') as f:\n",
    "    id2num = json.load(f)\n",
    "    num2id = {v:k for k, v in id2num.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate import compute_sim, evaluate, map_per_image, compute_simv2\n",
    "from evaluate import *\n",
    "\n",
    "if run_val:\n",
    "    score, val_sim_df = evaluate(train_df, train_embs, val_embs, norm=True)\n",
    "    val_sim_df[\"gt\"] = val_sim_df.image.map(val_map)\n",
    "    val_sim_df[\"map\"] = val_sim_df.apply(lambda row: map_per_image(row[\"gt\"], row.predictions.split(\" \")), axis=1)\n",
    "    val_sim_df = val_sim_df.sort_values(\"map\")\n",
    "    print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_val:\n",
    "    train_k, train_v = dict2list(train_embs)\n",
    "    test_k, test_v = dict2list(val_embs)\n",
    "    class_count_df = train_df.groupby('individual_id').size().to_frame('count').reset_index()\n",
    "    class_count = dict(zip(class_count_df.individual_id, class_count_df['count']))\n",
    "    print(train_v.shape, test_v.shape)\n",
    "    train_v = l2norm_numpy(train_v)\n",
    "    test_v = l2norm_numpy(test_v)\n",
    "    train_ids = np.unique([train_map[x] for x in train_k])\n",
    "    allowed = []\n",
    "    for i, k in enumerate(test_k):\n",
    "        if train_map[k] in train_ids:\n",
    "            allowed.append(i)\n",
    "    test_k, test_v = [test_k[i] for i in allowed], [test_v[i] for i in allowed]\n",
    "    cosines = np.matmul(test_v, train_v.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_border(img, color):\n",
    "    bordersize = 14\n",
    "    return cv2.copyMakeBorder(\n",
    "        img,\n",
    "        top=bordersize,\n",
    "        bottom=bordersize,\n",
    "        left=bordersize,\n",
    "        right=bordersize,\n",
    "        borderType=cv2.BORDER_CONSTANT,\n",
    "        value=color\n",
    "    )\n",
    "\n",
    "if run_val:\n",
    "    c = 0\n",
    "    for i, scores in enumerate(cosines):\n",
    "        if np.random.rand() < 0.1:\n",
    "            top = 7\n",
    "            sort_idx = np.argsort(-scores)\n",
    "            topk = [train_k[j] for j in sort_idx[:top]]\n",
    "            topk_score = [scores[j] for j in sort_idx[:top]]\n",
    "            topk_id = [train_map[x] for x in topk]\n",
    "            qid = test_k[i]\n",
    "            gt = train_map[qid]\n",
    "            c+=1\n",
    "            imgs = [cv2.imread(f'{train_img_dir}/{qid}')[:,:,::-1]]\n",
    "            for k, l in zip(topk, topk_id):\n",
    "                im = cv2.imread(f'{train_img_dir}/{k}')[:,:,::-1]\n",
    "                im = add_border(im, color=(255, 0, 0) if gt != l else (0, 128, 0))\n",
    "                imgs.append(im)\n",
    "            # Show image\n",
    "            fig = plt.figure(figsize=(25, 4))\n",
    "            columns = top + 1\n",
    "            rows = 1\n",
    "            for i2 in range(0, columns*rows):\n",
    "                fig.add_subplot(rows, columns, i2+1)\n",
    "                plt.title(f'{gt} {id_map[qid]}' if i2 == 0 else f'{topk_score[i2 - 1]:.2f} {id_map[topk[i2 -1]]}')\n",
    "                plt.imshow(imgs[i2])\n",
    "                plt.axis('off')\n",
    "            \n",
    "            plt.show()\n",
    "            \n",
    "        if c == 4:\n",
    "            break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_sim_df\n",
    "\n",
    "# sim_df = compute_sim(train_df, {**train_embs, **val_embs}, test_embs, thr=0.5, norm=True)\n",
    "# sim_df[[\"image\", \"predictions\"]].to_csv('submission.csv', index=False)\n",
    "# sim_df.head()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble from 4 models ['infer\\\\b5_pseudo_cutout_lb0.836', 'infer\\\\b5_pseudo_lb0.832', 'infer\\\\b5_pseudo_lb0.833', 'infer\\\\b6_pseudo_lb0.83x']\n",
      "Ensemble from 4 models ['infer\\\\b5_pseudo_cutout_lb0.836', 'infer\\\\b5_pseudo_lb0.832', 'infer\\\\b5_pseudo_lb0.833', 'infer\\\\b6_pseudo_lb0.83x']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NearestNeighbors(metric='cosine', n_neighbors=100)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# assert False\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "n_neighbors = 100\n",
    "knn = NearestNeighbors(n_neighbors=n_neighbors,metric='cosine')\n",
    "\n",
    "# diff fold\n",
    "db_embs = get_emb(infer_dirs, ['train', 'val'], weights)\n",
    "test_embs = get_emb(infer_dirs, 'test', weights)\n",
    "# test_pred = pickle_load(infer_dirs[0] + '/test_pred.pkl')\n",
    "test_pred = None\n",
    "# db_embs = {**train_embs, **val_embs}\n",
    "# db_embs = l2norm(db_embs)\n",
    "# test_embs = l2norm(test_embs)\n",
    "train_k, train_v = dict2list(db_embs)\n",
    "test_k, test_v = dict2list(test_embs)\n",
    "\n",
    "\n",
    "knn.fit(train_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances, idxs = knn.kneighbors(test_v, n_neighbors, return_distance=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27956/27956 [00:04<00:00, 5947.97it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>target</th>\n",
       "      <th>confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7a785b700b0339.jpg</td>\n",
       "      <td>c93996835aa8</td>\n",
       "      <td>0.999426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dd5f7eb1cbe207.jpg</td>\n",
       "      <td>84a261c0e5cf</td>\n",
       "      <td>0.999412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8de09ac45aa1df.jpg</td>\n",
       "      <td>7fdeba948ee8</td>\n",
       "      <td>0.999380</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                image        target  confidence\n",
       "0  7a785b700b0339.jpg  c93996835aa8    0.999426\n",
       "1  dd5f7eb1cbe207.jpg  84a261c0e5cf    0.999412\n",
       "2  8de09ac45aa1df.jpg  7fdeba948ee8    0.999380"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "test_df = []\n",
    "train_k = np.asarray(train_k)\n",
    "img2id = dict(zip(train_df.image, train_df.individual_id))\n",
    "\n",
    "for i in tqdm(range(len(test_k))):\n",
    "    dist, idx = distances[i], idxs[i]\n",
    "    for d, id in zip(dist, idx):\n",
    "        img_id = train_k[id]\n",
    "        tar = img2id[img_id]\n",
    "        if test_pred is not None:\n",
    "            pred = test_pred[test_k[i]]\n",
    "            top1_idx = np.argmax(pred)\n",
    "            top1_conf = pred[top1_idx]\n",
    "            top1_pred = num2id[top1_idx]\n",
    "            test_df.append([test_k[i], tar, d, top1_pred, top1_conf])\n",
    "        else:\n",
    "            test_df.append([test_k[i], tar, d])\n",
    "\n",
    "    \n",
    "cols = ['image', 'target', 'distances']\n",
    "if test_pred is not None:\n",
    "    cols += ['top1_pred', 'top1_conf']\n",
    "test_df = pd.DataFrame(test_df, columns=cols)\n",
    "raw_test_df = test_df.copy()\n",
    "test_df['confidence'] = 1-test_df['distances']\n",
    "test_df = test_df.groupby(cols[:2]).confidence.max().reset_index()\n",
    "test_df = test_df.sort_values('confidence',ascending=False).reset_index(drop=True)\n",
    "test_df.to_csv('test_neighbors.csv')\n",
    "test_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if test_pred is not None:\n",
    "#         t = test_df.groupby(['image']).first().reset_index()\n",
    "#         print((t['target'] == t['top1_pred']).mean())\n",
    "\n",
    "#         # Show images\n",
    "#         t = t.query('target != top1_pred & top1_conf >= 0.9')\n",
    "#         samples = t.sample(5)\n",
    "\n",
    "#         for i, row in samples.iterrows():\n",
    "#         # Show image\n",
    "#         fig = plt.figure(figsize=(25, 4))\n",
    "#         columns = 7\n",
    "#         rows = 1\n",
    "#         imgs = [cv2.imread(f'D:/whale384/test_images-384-384/test_images-384-384/{row[\"image\"]}')[:,:,::-1]]\n",
    "#         imgs+= [cv2.imread(f'D:/whale384/train_images-384-384/train_images-384-384/{x}')[:,:,::-1]\n",
    "#                 for x in train_df[train_df.individual_id == row['target']]['image'].values[:3]]\n",
    "#         imgs+= [cv2.imread(f'D:/whale384/train_images-384-384/train_images-384-384/{x}')[:,:,::-1]\n",
    "#                 for x in train_df[train_df.individual_id == row['top1_pred']]['image'].values[:3]]\n",
    "\n",
    "#         for i2 in range(0, columns*rows):\n",
    "#                 fig.add_subplot(rows, columns, i2+1)\n",
    "#                 s = row[\"confidence\"] if i2 < 4 else row[\"top1_conf\"]\n",
    "#                 plt.title(row[\"image\"] if i2 == 0 else f'{s:3f}')\n",
    "#                 if i2 < len(imgs):\n",
    "#                 plt.imshow(imgs[i2])\n",
    "#                 plt.axis('off')\n",
    "        \n",
    "#         plt.show()\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>target</th>\n",
       "      <th>confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7a785b700b0339.jpg</td>\n",
       "      <td>c93996835aa8</td>\n",
       "      <td>0.999426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dd5f7eb1cbe207.jpg</td>\n",
       "      <td>84a261c0e5cf</td>\n",
       "      <td>0.999412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8de09ac45aa1df.jpg</td>\n",
       "      <td>7fdeba948ee8</td>\n",
       "      <td>0.999380</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                image        target  confidence\n",
       "0  7a785b700b0339.jpg  c93996835aa8    0.999426\n",
       "1  dd5f7eb1cbe207.jpg  84a261c0e5cf    0.999412\n",
       "2  8de09ac45aa1df.jpg  7fdeba948ee8    0.999380"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def accum(x):\n",
    "    # if len(x) > 3 and np.max(x) < 0.51:\n",
    "    #     return np.max(x) - 0.002 * len(x)\n",
    "    r = np.sum([v ** (8 * (i + 1)) for i, v in enumerate(x)])\n",
    "    return r\n",
    "\n",
    "raw_test_df['confidence'] = 1 - raw_test_df['distances']\n",
    "test_df = raw_test_df.groupby(['image','target']).confidence.max().reset_index()\n",
    "test_df = test_df.sort_values(['confidence'], ascending=False).reset_index(drop=True)\n",
    "test_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THR: 0.49910000000000004: 0.21512376591787094\n"
     ]
    }
   ],
   "source": [
    "xt = test_df.groupby('image').confidence.max().reset_index()\n",
    "for thr in np.arange(0.0, 0.55, 0.0001):\n",
    "    r = len(xt[xt['confidence'] <= thr]) / len(xt)\n",
    "    if abs(r - 0.22) < 0.005:\n",
    "        print(f\"THR: {thr}: {r}\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1221178/1221178 [01:01<00:00, 19811.63it/s]\n",
      "100%|██████████| 27956/27956 [00:00<00:00, 1164906.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1079\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7a785b700b0339.jpg</td>\n",
       "      <td>c93996835aa8 new_individual 39af37a7f933 d36d5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dd5f7eb1cbe207.jpg</td>\n",
       "      <td>84a261c0e5cf new_individual cf0aca801a93 a8e1f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8de09ac45aa1df.jpg</td>\n",
       "      <td>7fdeba948ee8 new_individual 0f35764e14aa bb76b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>e9abb76a5bed89.jpg</td>\n",
       "      <td>35f898e6595e new_individual c737ccb75e16 87ad8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4a207f09a87442.jpg</td>\n",
       "      <td>29623de1f9a5 new_individual 2ed22956060f 7d842...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                image                                        predictions\n",
       "0  7a785b700b0339.jpg  c93996835aa8 new_individual 39af37a7f933 d36d5...\n",
       "1  dd5f7eb1cbe207.jpg  84a261c0e5cf new_individual cf0aca801a93 a8e1f...\n",
       "2  8de09ac45aa1df.jpg  7fdeba948ee8 new_individual 0f35764e14aa bb76b...\n",
       "3  e9abb76a5bed89.jpg  35f898e6595e new_individual c737ccb75e16 87ad8...\n",
       "4  4a207f09a87442.jpg  29623de1f9a5 new_individual 2ed22956060f 7d842..."
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = {}\n",
    "sample_list = ['938b7e931166', '5bf17305f073', '7593d2aee842', '7362d7a01d00','956562ff2888']\n",
    "\n",
    "for i,row in tqdm(test_df.iterrows(), total=len(test_df)):\n",
    "    if row.image in predictions:\n",
    "        if len(predictions[row.image])==5:\n",
    "            continue\n",
    "        predictions[row.image].append(row.target)\n",
    "    elif row.confidence >= thr:\n",
    "        predictions[row.image] = [row.target,'new_individual']\n",
    "    else:\n",
    "        predictions[row.image] = ['new_individual',row.target]\n",
    "\n",
    "c = 0\n",
    "for x in tqdm(predictions):\n",
    "    if len(predictions[x])<5:\n",
    "        c+=1\n",
    "        remaining = [y for y in sample_list if y not in predictions]\n",
    "        predictions[x] = predictions[x]+remaining\n",
    "        predictions[x] = predictions[x][:5]\n",
    "    predictions[x] = ' '.join(predictions[x])\n",
    "\n",
    "print(c)\n",
    "predictions = pd.Series(predictions).reset_index()\n",
    "predictions.columns = ['image','predictions']\n",
    "predictions.to_csv('submisstion3,csv',index=False)\n",
    "predictions.head()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0d4bc70c65d06e1543861fe65a0e2a7420176491a9e60a2c8babf4d7456b2d28"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
