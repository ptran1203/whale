{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import pickle_load\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from evaluate import compute_sim, evaluate\n",
    "\n",
    "def l2norm(embs):\n",
    "    return {k: v/np.linalg.norm(v) for k, v in embs.items()}\n",
    "\n",
    "infer_dir = 'D:'\n",
    "infer_dir = '/Users/macbook/Downloads'\n",
    "# infer_dir = 'C:/Users/msi/Downloads/drive-download-20220218T051534Z-001'\n",
    "\n",
    "train_embs = pickle_load(f\"{infer_dir}/train_embs.pkl\")\n",
    "test_embs = pickle_load(f\"{infer_dir}/test_embs.pkl\")\n",
    "val_embs = pickle_load(f\"{infer_dir}/val_embs.pkl\")\n",
    "train_df = pd.read_csv('data/train_kfold.csv')\n",
    "\n",
    "train_embs = l2norm(train_embs)\n",
    "test_embs = l2norm(test_embs)\n",
    "val_embs = l2norm(val_embs)\n",
    "# train_embs['00021adfb725ed.jpg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df = train_df[train_df.subset == 'test'].reset_index()\n",
    "val_map = dict(zip(val_df.image, val_df.individual_id))\n",
    "train_map = dict(zip(train_df.image, train_df.individual_id))\n",
    "# val_imgs = val_df.image.unique()\n",
    "# val_embs = {k: train_embs[k] for k in val_imgs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5710/5710 [00:06<00:00, 922.52it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6240776415645066"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from evaluate import compute_sim, evaluate, map_per_image\n",
    "\n",
    "score, val_sim_df = evaluate(train_df, train_embs, val_embs)\n",
    "val_sim_df[\"gt\"] = val_sim_df.image.map(val_map)\n",
    "val_sim_df[\"map\"] = val_sim_df.apply(lambda row: map_per_image(row[\"gt\"], row.predictions.split(\" \")), axis=1)\n",
    "val_sim_df = val_sim_df.sort_values(\"map\")\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x12b61b9a0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWAAAAFgCAYAAACFYaNMAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAVrElEQVR4nO3df/BddX3n8edLIuiuVKCkDBvCBmtsG+0WnG8R0d1VqRCYaYNb5cduJTi0oS106rTbGdSZxdVlt+1U3bVDKemSIXSsQBWX1LKwEbFMi/yISoGAlK/82CQgCT9Ed53SBt/7xz3Z3oZvkpvknvv5fvN9PmbufM95nx/3/Znvlxcn555zbqoKSdLkvaJ1A5I0XxnAktSIASxJjRjAktSIASxJjSxo3UAfli9fXjfffHPrNiRph8xUPCCPgJ955pnWLUjSHh2QASxJc4EBLEmNGMCS1IgBLEmNGMCS1IgBLEmNGMCS1IgBLEmNGMCS1IgBLEmNGMCS1IgBLEmNGMCS1IgBLOmAtmjxsSQZy2vR4mPH2tsB+TxgSdrhyc2bOPvKO8ayr+suPHks+9nBI2BJasQAlqRGDGBJasQAlqRGDGBJasQAlqRGDGBJasQAlqRGDGBJasQAlqRGDGBJasQAlqRGDGBJasQAlqRGDGBJasQAlqRGDGBJasQAlqRGDGBJasQAlqRGegvgJK9KcneSv06yMcl/7OrHJbkryXSS65Ic3NUP6eanu+VLhvb1oa7+cJLT+upZkiapzyPgF4F3VdVPAccDy5OcBPwO8Kmqej3wPHBBt/4FwPNd/VPdeiRZBpwDvBFYDvxBkoN67FuSJqK3AK6B/9PNvrJ7FfAu4HNdfS1wZje9opunW35KknT1a6vqxap6DJgGTuyrb0malF7PASc5KMm9wFZgPfAt4DtVtb1bZTOwqJteBGwC6Ja/APzwcH2GbSRpzuo1gKvqpao6HjiGwVHrj/f1XklWJdmQZMO2bdv6ehtJGpuJXAVRVd8BbgPeChyWZEG36BhgSze9BVgM0C1/LfDscH2GbYbfY3VVTVXV1MKFC/sYhiSNVZ9XQSxMclg3/Wrg3cBDDIL4vd1qK4Ebu+l13Tzd8i9XVXX1c7qrJI4DlgJ399W3JE3Kgj2vss+OBtZ2Vyy8Ari+qr6Y5EHg2iT/CfgGcFW3/lXAHyeZBp5jcOUDVbUxyfXAg8B24KKqeqnHviVpInoL4Kq6DzhhhvqjzHAVQ1X9LfC+XezrMuCycfcoSS15J5wkNWIAS1IjBrAkNWIAS1IjBrAkNWIAS1IjBrAkNWIAS1IjBrAkNWIAS1IjBrAkNWIAS1IjBrAkNWIAS1IjBrAkNWIAS1IjBrAkNWIAS1IjBrAkNWIAS1IjBrAkNWIAS1IjBrAkNWIAS1IjBrAkNWIAS1IjBrAkNWIAS1IjBrAkNWIAS1IjBrAkNWIAS1IjBrAkNWIAS1IjBrAkNWIAS1IjvQVwksVJbkvyYJKNSX69q380yZYk93avM4a2+VCS6SQPJzltqL68q00nuaSvniVpkhb0uO/twG9W1deTHAp8Lcn6btmnqur3hldOsgw4B3gj8M+ALyV5Q7f4cuDdwGbgniTrqurBHnuXpN71FsBV9RTwVDf9vSQPAYt2s8kK4NqqehF4LMk0cGK3bLqqHgVIcm23rgEsaU6byDngJEuAE4C7utLFSe5LsibJ4V1tEbBpaLPNXW1X9Z3fY1WSDUk2bNu2bdxDkKSx6z2Ak7wG+Dzwwar6LnAF8KPA8QyOkD8xjvepqtVVNVVVUwsXLhzHLiWpV32eAybJKxmE72eq6gaAqnp6aPkfAV/sZrcAi4c2P6arsZu6JM1ZfV4FEeAq4KGq+uRQ/eih1d4DPNBNrwPOSXJIkuOApcDdwD3A0iTHJTmYwQd16/rqW5Impc8j4LcB7wfuT3JvV/swcG6S44ECHgcuBKiqjUmuZ/Dh2nbgoqp6CSDJxcAtwEHAmqra2GPfkjQRfV4F8ZdAZlh00262uQy4bIb6TbvbTpLmIu+Ek6RGDGBJasQAlqRGDGBJasQAlqRGDGBJasQAlqRGDGBJasQAlqRGDGBJasQAlqRGDGBJasQAlqRGDGBJasQAlqRGDGBJasQAlqRGDGBJasQAlqRGDGBJasQAlqRGDGBJasQAlqRGDGBJasQAlqRGDGBJasQAlqRGDGBJasQAlqRGDGBJasQAlqRGDGBJasQAlqRGDGBJasQAlqRGDGBJaqS3AE6yOMltSR5MsjHJr3f1I5KsT/JI9/Pwrp4kn04yneS+JG8e2tfKbv1Hkqzsq2dJmqQ+j4C3A79ZVcuAk4CLkiwDLgFuraqlwK3dPMDpwNLutQq4AgaBDVwKvAU4Ebh0R2hL0lzWWwBX1VNV9fVu+nvAQ8AiYAWwtlttLXBmN70CuKYG7gQOS3I0cBqwvqqeq6rngfXA8r76lqRJmcg54CRLgBOAu4CjquqpbtG3gaO66UXApqHNNne1XdV3fo9VSTYk2bBt27bxDkCSetB7ACd5DfB54INV9d3hZVVVQI3jfapqdVVNVdXUwoULx7FLSepVrwGc5JUMwvczVXVDV366O7VA93NrV98CLB7a/Jiutqu6JM1pfV4FEeAq4KGq+uTQonXAjisZVgI3DtXP666GOAl4oTtVcQtwapLDuw/fTu1qkjSnLehx328D3g/cn+TervZh4LeB65NcADwBnNUtuwk4A5gGvg98AKCqnkvyceCebr2PVdVzPfYtSRPRWwBX1V8C2cXiU2ZYv4CLdrGvNcCa8XUnSe15J5wkNWIAS1IjBrAkNWIAS1IjBrAkNWIAS1IjIwVwkreNUpMkjW7UI+DfH7EmSRrRbm/ESPJW4GRgYZLfGFr0Q8BBfTYmSQe6Pd0JdzDwmm69Q4fq3wXe21dTkjQf7DaAq+ovgL9IcnVVPTGhniRpXhj1WRCHJFkNLBnepqre1UdTkjQfjBrAfwr8IfDfgZf6a0eS5o9RA3h7VV3RayeSNM+MehnanyX51SRHd18rf0T3bcWSpH006hHwjm+w+K2hWgGvG287kjR/jBTAVXVc341I0nwzUgAnOW+melVdM952JGn+GPUUxE8PTb+KwVcKfR0wgCVpH416CuLXhueTHAZc20dDkjRf7OvjKP8v4HlhSdoPo54D/jMGVz3A4CE8PwFc31dTkjQfjHoO+PeGprcDT1TV5h76kaR5Y6RTEN1Deb7J4IlohwN/12dTkjQfjPqNGGcBdwPvA84C7kri4yglaT+MegriI8BPV9VWgCQLgS8Bn+urMUk60I16FcQrdoRv59m92FaSNINRj4BvTnIL8Nlu/mzgpn5akqT5YU/fCfd64Kiq+q0k/wZ4e7foq8Bn+m5Okg5kezoC/q/AhwCq6gbgBoAkP9kt+9kee5OkA9qezuMeVVX371zsakt66UiS5ok9BfBhu1n26jH2IUnzzp4CeEOSX9q5mOQXga/105IkzQ97Ogf8QeALSf4d/xC4U8DBwHt67EuSDni7DeCqeho4Ock7gTd15T+vqi/33pkkHeBGfRbEbVX1+91rpPBNsibJ1iQPDNU+mmRLknu71xlDyz6UZDrJw0lOG6ov72rTSS7Zm8FJ0mzW591sVwPLZ6h/qqqO7143ASRZBpwDvLHb5g+SHJTkIOBy4HRgGXBut64kzXmj3gm316rq9iRLRlx9BXBtVb0IPJZkGjixWzZdVY8CJLm2W/fBcfcrSZPW4nkOFye5rztFcXhXWwRsGlpnc1fbVf1lkqxKsiHJhm3btvXRtySN1aQD+ArgR4HjgaeAT4xrx1W1uqqmqmpq4cKF49qtJPWmt1MQM+muqgAgyR8BX+xmtwCLh1Y9pquxm7okzWkTPQJOcvTQ7HuAHVdIrAPOSXJIkuOApQweAH8PsDTJcUkOZvBB3bq++lu0+FiSjOW1aPGxfbUp6QDR2xFwks8C7wCOTLIZuBR4R5LjGXzB5+PAhQBVtTHJ9Qw+XNsOXFRVL3X7uRi4hcGXga6pqo199fzk5k2cfeUdY9nXdReePJb9SDpw9XkVxLkzlK/azfqXAZfNUL8Jnz0s6QDkt1pIUiMGsCQ1YgBLUiMGsCQ1YgBLUiMGsCQ1YgBLUiMGsCQ1YgBLUiMGsCQ1YgBLUiMGsCQ1YgBLUiMGsCQ1YgBLUiMGsCQ1YgBLUiMGsCQ1YgBLUiMGsCQ1YgBLUiMGsCQ1YgBLUiMGsCQ1YgBLUiMGsCQ1YgBLUiMGsCQ1YgBLUiMGsCQ1YgBLUiMGsCQ1YgBLUiMGsCQ1YgBLUiMGsCQ10lsAJ1mTZGuSB4ZqRyRZn+SR7ufhXT1JPp1kOsl9Sd48tM3Kbv1Hkqzsq19JmrQ+j4CvBpbvVLsEuLWqlgK3dvMApwNLu9cq4AoYBDZwKfAW4ETg0h2hLUlzXW8BXFW3A8/tVF4BrO2m1wJnDtWvqYE7gcOSHA2cBqyvqueq6nlgPS8PdUmakyZ9Dvioqnqqm/42cFQ3vQjYNLTe5q62q/rLJFmVZEOSDdu2bRtv15LUg2YfwlVVATXG/a2uqqmqmlq4cOG4ditJvZl0AD/dnVqg+7m1q28BFg+td0xX21Vdkua8SQfwOmDHlQwrgRuH6ud1V0OcBLzQnaq4BTg1yeHdh2+ndjVJmvMW9LXjJJ8F3gEcmWQzg6sZfhu4PskFwBPAWd3qNwFnANPA94EPAFTVc0k+DtzTrfexqtr5gz1JmpN6C+CqOncXi06ZYd0CLtrFftYAa8bYmiTNCt4JJ0mNGMCS1IgBLEmNGMCS1IgBLEmNGMCS1IgBLEmNGMCS1IgBLEmNGMCS1IgBLEmNGMCS1IgBLEmNGMCS1IgBLEmNGMCS1IgBLEmNGMCS1IgBLEmNGMCS1IgBLEmNGMCS1IgBLEmNGMCS1IgBLEmNGMCS1IgBLEmNGMCS1IgBLEmNGMCS1IgBLEmNGMCS1IgBLEmNGMCS1IgBrH22aPGxJBnLa9HiY1sPR5q4BS3eNMnjwPeAl4DtVTWV5AjgOmAJ8DhwVlU9nyTAfwPOAL4PnF9VX2/Rt/6xJzdv4uwr7xjLvq678OSx7EeaS1oeAb+zqo6vqqlu/hLg1qpaCtzazQOcDiztXquAKybeqST1YDadglgBrO2m1wJnDtWvqYE7gcOSHN2gP0kaq1YBXMD/SvK1JKu62lFV9VQ3/W3gqG56EbBpaNvNXe0fSbIqyYYkG7Zt29ZX35I0Nk3OAQNvr6otSX4EWJ/km8MLq6qS1N7ssKpWA6sBpqam9mpbSWqhyRFwVW3pfm4FvgCcCDy949RC93Nrt/oWYPHQ5sd0NUma0yYewEn+aZJDd0wDpwIPAOuAld1qK4Ebu+l1wHkZOAl4YehUhSTNWS1OQRwFfGFwdRkLgD+pqpuT3ANcn+QC4AngrG79mxhcgjbN4DK0D0y+ZUkav4kHcFU9CvzUDPVngVNmqBdw0QRak6SJmk2XoUnSvGIAS1IjBrAkNWIAS1IjBrAkNWIAS1IjBrAkNWIAS1IjBrAkNWIAS1IjBrAkNWIAS1IjBrAkNWIAS1IjBrAkNWIAS1IjBrAkNWIAS1IjBvA8s2jxsSQZy0vS/mnxpZxq6MnNmzj7yjvGsq/rLjx5LPuR5iuPgCWpEQNYkhoxgCWpEQNYkhoxgCWpEQN4DvDSMenA5GVoc4CXjkkHJo+AJakRA1iSGjGAJakRA1iSGjGAJakRA1iSGjGAJakRA1iSGjGAJamRORPASZYneTjJdJJLWvcjSftrTgRwkoOAy4HTgWXAuUmWte1KkvbPnAhg4ERguqoeraq/A64FVjTuSZL2S6qqdQ97lOS9wPKq+sVu/v3AW6rq4qF1VgGrutkfAx7eh7c6EnhmP9udbRzT3OCY5oZ9HdMzVbV85+IB8zS0qloNrN6ffSTZUFVTY2ppVnBMc4NjmhvGPaa5cgpiC7B4aP6YriZJc9ZcCeB7gKVJjktyMHAOsK5xT5K0X+bEKYiq2p7kYuAW4CBgTVVt7OGt9usUxizlmOYGxzQ3jHVMc+JDOEk6EM2VUxCSdMAxgCWpkXkXwHu6pTnJIUmu65bflWRJgzb32gjj+o0kDya5L8mtSf55iz73xqi3nyf5+SSVZNZf8jTKmJKc1f2uNib5k0n3uLdG+Ns7NsltSb7R/f2d0aLPvZFkTZKtSR7YxfIk+XQ35vuSvHmf3qiq5s2LwQd43wJeBxwM/DWwbKd1fhX4w276HOC61n2PaVzvBP5JN/0rs31co4ypW+9Q4HbgTmCqdd9j+D0tBb4BHN7N/0jrvscwptXAr3TTy4DHW/c9wrj+FfBm4IFdLD8D+J9AgJOAu/blfebbEfAotzSvANZ2058DTkmSCfa4L/Y4rqq6raq+383eyeBa6tls1NvPPw78DvC3k2xuH40ypl8CLq+q5wGqauuEe9xbo4ypgB/qpl8LPDnB/vZJVd0OPLebVVYA19TAncBhSY7e2/eZbwG8CNg0NL+5q824TlVtB14Afngi3e27UcY17AIG//eezfY4pu6ffYur6s8n2dh+GOX39AbgDUn+KsmdSV52++osM8qYPgr8QpLNwE3Ar02mtV7t7X9zM5oT1wFrfJL8AjAF/OvWveyPJK8APgmc37iVcVvA4DTEOxj8K+X2JD9ZVd9p2dR+Ohe4uqo+keStwB8neVNV/aB1Y63NtyPgUW5p/v/rJFnA4J9Mz06ku3030q3aSX4G+Ajwc1X14oR621d7GtOhwJuAryR5nMF5uHWz/IO4UX5Pm4F1VfX3VfUY8DcMAnm2GmVMFwDXA1TVV4FXMXiozVw2lscjzLcAHuWW5nXAym76vcCXqzvrPovtcVxJTgCuZBC+s/28IuxhTFX1QlUdWVVLqmoJg/PaP1dVG9q0O5JR/v7+B4OjX5IcyeCUxKMT7HFvjTKm/w2cApDkJxgE8LaJdjl+64DzuqshTgJeqKqn9novrT9tbPDp5hkMjiq+BXykq32MwX+8MPjj+FNgGrgbeF3rnsc0ri8BTwP3dq91rXve3zHttO5XmOVXQYz4ewqDUysPAvcD57TueQxjWgb8FYMrJO4FTm3d8whj+izwFPD3DP5VcgHwy8AvD/2eLu/GfP++/u15K7IkNTLfTkFI0qxhAEtSIwawJDViAEtSIwawJDViAEtSIwawJDViAGveSbIkyTeTXJ3kb5J8JsnPdA/AeSTJid3rq90zbO9I8mPdtucnuTHJV7p1L209Hs1dBrDmq9cDnwB+vHv9W+DtwL8HPgx8E/iXVXUC8B+A/zy07YnAzwP/AnjfLH/+hGYxn4am+eqxqrofIMlG4NaqqiT3A0sYPIRpbZKlDJ5n+8qhbddX1bPdtjcwCO7Z/AwKzVIeAWu+Gn4a3A+G5n/A4MDk48BtVfUm4GcZPCNkh53v3/d+fu0TA1ia2Wv5h8cLnr/TsncnOSLJq4EzGTxoRtprBrA0s98F/kuSb/DyU3V3A58H7gM+X7P7EZiaxXwamrQXkpzP4NGDF7fuRXOfR8CS1IhHwJLUiEfAktSIASxJjRjAktSIASxJjRjAktTI/wNnV2aNo3xC3gAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "val_sim_df = val_sim_df.sort_values(\"map\")\n",
    "sns.displot(val_sim_df.map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27956/27956 [00:33<00:00, 843.32it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8287f2ebd39ded.jpg</td>\n",
       "      <td>37c7aba965a5 new_individual ce6e37904aa4 ee5da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d36ac529c9e164.jpg</td>\n",
       "      <td>723be0215bcf new_individual 1394c7e5fb92 711bd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4cbcd5b2907e97.jpg</td>\n",
       "      <td>600ab1de92d9 new_individual c995c043c353 a5997...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a0e54364d99434.jpg</td>\n",
       "      <td>aa5a25cecec5 new_individual 24698eb627d3 5f052...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4517add5ebd287.jpg</td>\n",
       "      <td>d752129e2df2 new_individual a68659015983 8fda3...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                image                                        predictions\n",
       "0  8287f2ebd39ded.jpg  37c7aba965a5 new_individual ce6e37904aa4 ee5da...\n",
       "1  d36ac529c9e164.jpg  723be0215bcf new_individual 1394c7e5fb92 711bd...\n",
       "2  4cbcd5b2907e97.jpg  600ab1de92d9 new_individual c995c043c353 a5997...\n",
       "3  a0e54364d99434.jpg  aa5a25cecec5 new_individual 24698eb627d3 5f052...\n",
       "4  4517add5ebd287.jpg  d752129e2df2 new_individual a68659015983 8fda3..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# val_sim_df\n",
    "sim_df = compute_sim(train_df, train_embs, test_embs)\n",
    "sim_df[[\"image\", \"predictions\"]].to_csv(\"submission.csv\", index=False)\n",
    "sim_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/_m/nvwstqcd6vx474nsyx49ljmc0000gn/T/ipykernel_17488/33248567.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0mrandom_show\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_sim_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_val\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;31m# random_show(sim_df, is_val=False)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/_m/nvwstqcd6vx474nsyx49ljmc0000gn/T/ipykernel_17488/33248567.py\u001b[0m in \u001b[0;36mrandom_show\u001b[0;34m(sim_df, is_val)\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0msim_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msim_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msim_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"map\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msim_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msim_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mimg1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'D:/whale_data/train_images-384-384/train_images-384-384/{sample.image}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"GT\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"gt\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"map\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "def random_show(sim_df, is_val=False):\n",
    "    sim_df = sim_df.copy()\n",
    "    if is_val:\n",
    "        sim_df = sim_df[sim_df[\"map\"] < 0.5]\n",
    "        sample = sim_df.iloc[np.random.choice(sim_df.index)]\n",
    "        img1 = cv2.imread(f'D:/whale_data/train_images-384-384/train_images-384-384/{sample.image}')[:, :, ::-1]\n",
    "        print(\"GT\", sample[\"gt\"], sample[\"map\"])\n",
    "    else:\n",
    "        sample = sim_df.iloc[np.random.choice(sim_df.index)]\n",
    "        img1 = cv2.imread(f'D:/whale_data/test_images-384-384/test_images-384-384/{sample.image}')[:, :, ::-1]\n",
    "        \n",
    "    imgs = [img1]\n",
    "\n",
    "    ids = sample.predictions.split(\" \")\n",
    "    for i in range(5):\n",
    "        if ids[i] != 'new_individual':\n",
    "            path = train_df[train_df.individual_id == ids[i]].values[0][0]\n",
    "            img = cv2.imread(f'D:/whale_data/train_images-384-384/train_images-384-384/{path}')[:, :, ::-1]\n",
    "            imgs.append(img)\n",
    "\n",
    "    fig = plt.figure(figsize=(8, 6))\n",
    "    columns = 3\n",
    "    rows = 2\n",
    "    for i in range(0, columns*rows):\n",
    "        fig.add_subplot(rows, columns, i+1)\n",
    "        if i == 0:\n",
    "            plt.title('Input')\n",
    "        else:\n",
    "            plt.title(ids[i-1])\n",
    "        if i < len(imgs):\n",
    "            \n",
    "            plt.imshow(imgs[i])\n",
    "    plt.show()\n",
    "\n",
    "random_show(val_sim_df, is_val=True)\n",
    "# random_show(sim_df, is_val=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "No active exception to reraise",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_948/3038769261.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mneighbors\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mNearestNeighbors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mknn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNearestNeighbors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_neighbors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmetric\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'cosine'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mtrain_k\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_v\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict2list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_embs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: No active exception to reraise"
     ]
    }
   ],
   "source": [
    "raise\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "knn = NearestNeighbors(n_neighbors=100,metric='cosine')\n",
    "\n",
    "train_k, train_v = dict2list(train_embs)\n",
    "test_k, test_v = dict2list(test_embs)\n",
    "knn.fit(train_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances, idxs = knn.kneighbors(test_v, 100, return_distance=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = []\n",
    "train_k = np.asarray(train_k)\n",
    "img2id = dict(zip(train_df.image, train_df.individual_id))\n",
    "\n",
    "for i in tqdm(range(len(test_k))):\n",
    "    dist, idx = distances[i], idxs[i]\n",
    "    for d, id in zip(dist, idx):\n",
    "        img_id = train_k[id]\n",
    "        tar = img2id[img_id]\n",
    "        test_df.append([test_k[i], tar, d]) \n",
    "    \n",
    "\n",
    "test_df = pd.DataFrame(test_df, columns=['image', 'target', 'distances'])\n",
    "test_df['confidence'] = 1-test_df['distances']\n",
    "test_df = test_df.groupby(['image','target']).confidence.max().reset_index()\n",
    "test_df = test_df.sort_values('confidence',ascending=False).reset_index(drop=True)\n",
    "test_df.to_csv('test_neighbors.csv')\n",
    "test_df.image.value_counts().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_list = ['938b7e931166', '5bf17305f073', '7593d2aee842', '7362d7a01d00','956562ff2888']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = {}\n",
    "for i,row in tqdm(test_df.iterrows(), total=len(test_df)):\n",
    "    if row.image in predictions:\n",
    "        if len(predictions[row.image])==5:\n",
    "            continue\n",
    "        predictions[row.image].append(row.target)\n",
    "    elif row.confidence > 0.5:\n",
    "        predictions[row.image] = [row.target,'new_individual']\n",
    "    else:\n",
    "        predictions[row.image] = ['new_individual',row.target]\n",
    "\n",
    "for x in tqdm(predictions):\n",
    "    if len(predictions[x])<5:\n",
    "        remaining = [y for y in sample_list if y not in predictions]\n",
    "        predictions[x] = predictions[x]+remaining\n",
    "        predictions[x] = predictions[x][:5]\n",
    "    predictions[x] = ' '.join(predictions[x])\n",
    "    \n",
    "predictions = pd.Series(predictions).reset_index()\n",
    "predictions.columns = ['image','predictions']\n",
    "predictions.to_csv('submission.csv',index=False)\n",
    "predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sim_df = sim_df.sort_values('image')\n",
    "# sim_df.to_csv('submission.csv', index=False)\n",
    "\n",
    "# s655_df = pd.read_csv('submission_655.csv')\n",
    "# s655_df= s655_df.sort_values('image')\n",
    "# s655_df.to_csv('submission_655.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0d4bc70c65d06e1543861fe65a0e2a7420176491a9e60a2c8babf4d7456b2d28"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
